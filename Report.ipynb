{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAQ's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Which insights did you gain from your EDA?\n",
    "\n",
    "While I was conducting the Exploratory Data Analysis on the financial fraud dataset, I noticed the following aspects: \n",
    "\n",
    "The dataset comprises various transaction types, with 'PAYMENT,' 'TRANSFER,' and 'CASH_OUT' being prominent. The distribution of transaction amounts revealed a range of common values and potential outliers. Analysis of fraudulent transactions, indicated by the 'isFraud' column, shed light on the prevalence of fraud in the dataset. Exploring flagged fraud transactions, as shown by 'isFlaggedFraud,' provided insights into any specific criteria for flagging. Examining changes in account balances before and after transactions, along with temporal analysis using the 'step' column, contributed to a better understanding of transaction patterns over time. The dataset also allowed for exploration of transaction destinations through the 'nameDest' column. This EDA serves as a foundation for further investigations into the nuances of financial activities, with potential applications in fraud detection and risk management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. How did you determine which columns to drop or keep? If your EDA\n",
    "informed this process, explain which insights you used to determine\n",
    "which columns were not needed.\n",
    "\n",
    "In determining which columns to drop or keep during the EDA, I considered several factors based on the insights gained from the analysis:\n",
    "\n",
    "I assessed the relevance of each column to the primary objectives of my analysis. Columns like 'step' and 'type' were retained as they provide critical temporal and categorical information. 'Amount' and the balance-related columns ('oldbalanceOrg,' 'newbalanceOrig,' 'oldbalanceDest,' 'newbalanceDest') were deemed essential for transaction analysis. The 'isFraud' column was crucial for identifying fraudulent transactions. However, if 'isFlaggedFraud' was found to have limited variability or relevance, it might be considered for removal. Plus, columns like 'nameOrig' and 'nameDest' were evaluated for their contribution to the analysis, with consideration given to potential privacy concerns or if they didn't significantly contribute to the insights. The decision to drop or keep columns was a necessary process in ensuring that the retained features were relevant, informative, and aligned with the objectives of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Which hyperparameter tuning strategy did you use? Grid-search or\n",
    "random-search? Why?\n",
    "\n",
    "In optimizing the hyperparameters for my model, I employed the grid-search strategy. \n",
    "\n",
    "Grid-search involves systematically searching through a predefined set of hyperparameter values for a model. I chose this strategy because it exhaustively explores all possible combinations of hyperparameter values within the specified ranges. While grid-search can be computationally intensive (with my measly 8 gigabytes of ram and leaving my laptop on overnight...), it ensures a thorough exploration of the hyperparameter space, allowing me to find the combination that yields the best performance for my specific model and dataset. This approach is particularly suitable when the hyperparameter search space is reasonably sized, and computational resources permit a comprehensive exploration. By conducting a grid-search, I aimed to identify the most effective hyperparameters for enhancing the performance of my model, ultimately leading to better predictive capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. How did your model's performance change after discovering optimal\n",
    "hyperparameters?\n",
    "\n",
    "After discovering and implementing the optimal hyperparameters through the grid-search strategy, my model's performance experienced notable improvements. The optimized hyperparameters led to a refined configuration that enhanced the model's ability to capture complex patterns and relationships within the dataset. This resulted in increased accuracy, precision, recall, or other relevant performance metrics, depending on the specific objectives of the model. The model became more robust, making better predictions on both the training and testing datasets. The optimized hyperparameters contributed to better generalization, reducing overfitting and improving the model's performance on unseen data. The process of hyperparameter tuning significantly elevated the effectiveness of my model, aligning it more closely with the underlying patterns in the data and improving its overall predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v. What was your final F1 Score?\n",
    "\n",
    "In my analysis, I utilized a grid search to find the optimal hyperparameters for a Random Forest Classifier. The best model obtained from this search was then evaluated on a test set to calculate the F1 score. The F1 score is 0.8695652173913044 and it is valuable in binary classification scenarios, striking a balance between precision and recall."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
